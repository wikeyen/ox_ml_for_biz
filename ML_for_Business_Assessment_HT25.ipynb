{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wikeyen/ox_ml_for_biz/blob/master/ML_for_Business_Assessment_HT25.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9g9aU3pdTmBv"
      },
      "source": [
        "# Machine Learning for Business - Assessment Notebook HT25\n",
        "\n",
        "This is the assigment of the class. You can go through the code by executing each one of the cells. We start the notebook describing the setting and providing you with the context of the exercise. At the end, you will find the questions that you need to answer and further information on your final deliverable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2W15uWBT5W7"
      },
      "source": [
        "### Please enter your candidate number below:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWmVpfkjT5FX"
      },
      "source": [
        "*(Enter your candidate number here)*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJQm41x1630A"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b91zfYfjgvKa"
      },
      "source": [
        "# 1. The Assignment Setting\n",
        "\n",
        "Our assignment is centered around a major problem in the management of retailer inventory. Specifically, we will explore the application of machine learning techniques as a method to identify and correct inventory record errors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TA7DNK29UVBj"
      },
      "source": [
        "## Your Role in this Exercise\n",
        "\n",
        "Imagine that you serve as the head of the Inventory Division of a leading grocery retailer with about 450 large stores across Europe. Your team is responsible for managing the inventory operations of the organization. One of the major challenges that your team aims to address is the issue of inventory errors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5nePlEHgkQz"
      },
      "source": [
        "## The Business Challenge: Inventory Errors\n",
        "\n",
        "Ensuring the availability of fast-moving items is essential for grocery retailers like your company. To this end, maintaining accurate inventory records has been, and remains, a central problem for managing retail operations. In many cases, however, retailers are unable to make accurate reordering decisions because their inventory records (i.e., how much is actually available on the shelf) are inaccurate. These discrepancies between the physical and recorded stock lead to poor reordering decisions and the over- or understocking of products that increase waste or lost sales, respectively."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74MjTiDzhmSa"
      },
      "source": [
        "## An Opportunity to Apply Machine Learning\n",
        "\n",
        "You recently hired a data scientist (Anna) in your team to explore how data-driven tools, like machine learning, could improve business operations. After six months of work, Anna is called to present the progress she has made. She is arguing that machine learning can solve the inventory errors problem via models that predict the likelihood of records with potential discrepancies between the amount of stock registered in the inventory records and the amount of stock actually on the shelf. She claims that being able to predict potential discrepancies will allow stores to correct emerging out-of-stock scenarios quickly and by reordering products accordingly.\n",
        "\n",
        "Specifically, she shares with you the following notebook, suggesting that she can now predict potential errors in the inventory stock at the SKU level. In her work, she is using a dataset that was created by your team that includes information at the SKU (stock-keeping unit) level about actual sales, forecast sales, and product size, among others.\n",
        "\n",
        "Currently, Anna is the only member of your team who is an expert on ML. Given that you are her direct manager and have experience in Analytics and Machine Learning during your MBA at SBS, you have asked Anna to share her coding notebook with you in advance so that you can look into it in preparation for your meeting.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5uA85f0jE7J"
      },
      "source": [
        "## Your Task\n",
        "\n",
        "Run the Python code in the following cells similarly to how we do it in the classroom and try to get a good understanding of it. This is the first part of your assignment. You can use BARD or ChatGPT if you encounter any difficulties in interpreting parts of the code. However, you are expected to conduct the review and write the report on your own. Once you run all the commands, your assignment will be to answer the respective questions described at the end of the notebook and submit your report to us.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZyTl1h-o9Wd"
      },
      "source": [
        "# 2. Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41H5rDelpAQQ"
      },
      "source": [
        "### Import libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rrH_Uh6qC3p"
      },
      "source": [
        "Import libraries for managing data structures and plotting figures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "usJlqbBWmwk4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCzj1zEVpHN3"
      },
      "source": [
        "### Import the dataset\n",
        "\n",
        "Note that all the values for continuous variables have been normalized to facilitate the algorithm training process. Thus, they do not reflect the actual numbers that were recorded by the business."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c_Z_wWQyn-IZ"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(f\"https://drive.google.com/uc?id=15akNjGB2rSjQwz7sXsWevZk0xDqarNja\", encoding=\"utf-8\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **dictionary** for the dataset is located here: [DataDictionary](https://docs.google.com/document/d/1AkvZHloktsCa6Tu0p7IkcXpyOM4zMGuJ/edit?usp=sharing&ouid=107468850368923160966&rtpof=true&sd=true)"
      ],
      "metadata": {
        "id": "ZNLcEOV0IQ6t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JOfxhCMoqr3J"
      },
      "outputs": [],
      "source": [
        "data.head(6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNln7mzGqvO1"
      },
      "source": [
        "# 3. Data exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66M1iLY7d9gM"
      },
      "source": [
        "### Numerical exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yx0wq4z2q4tY"
      },
      "source": [
        "Number of columns and rows in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l9tbd43Sq6UV"
      },
      "outputs": [],
      "source": [
        "print('Data size : ', data.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfdqajYzrmcs"
      },
      "source": [
        "Checking for missing values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mI2pvcozq61e"
      },
      "outputs": [],
      "source": [
        "print('Null values per column : \\n', data.isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3d8fUnN3L_hS"
      },
      "source": [
        "Get an overview of all the variables in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jSM4pK-yrDYD"
      },
      "outputs": [],
      "source": [
        "data.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5izKLnbMHP9"
      },
      "source": [
        "Removing values in the data with NAs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f_vrd4XyixbX"
      },
      "outputs": [],
      "source": [
        "data = data.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OmobcKssbkSL"
      },
      "outputs": [],
      "source": [
        "print('\\nBalance of positive and negative error classes (%): \\n',\n",
        "      data['stock_error'].value_counts(normalize=True) * 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Htj8Obdd1W7"
      },
      "source": [
        "### Splitting the data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nz9VVzYUdrcb"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQjr01n4vhtL"
      },
      "source": [
        "Splitting the independent from the target variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CZXYCSltjAYD"
      },
      "outputs": [],
      "source": [
        "X = data.drop(['stock_error'], axis = 1)\n",
        "target = data['stock_error']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFbhcZTCo5ho"
      },
      "source": [
        "Let's perform one-hot-encoding to ensure that all the variables in the dataset are in numerical format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YwjiuL70pBXm"
      },
      "outputs": [],
      "source": [
        "cat = X.select_dtypes(include='O').keys()\n",
        "X_new = pd.get_dummies(X, columns = cat, drop_first=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5P6iKIayveUK"
      },
      "source": [
        "Splitting the data into our training and testing data sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MaIweemijAeP"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_new,\n",
        "                                                    target,\n",
        "                                                    test_size = 0.3,\n",
        "                                                    random_state = 44,\n",
        "                                                    stratify=target)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQflnLVmwMGx"
      },
      "source": [
        "Check: how many observations are included in our training and testing sets?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dDlMhIb0q1ZI"
      },
      "outputs": [],
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOehqSRUcF4Q"
      },
      "source": [
        "# 4. Training of Algorithm # 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2fAIE7uhDJK"
      },
      "source": [
        "### Loading the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gSAOB_oodW2w"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wR6dkP79io0W"
      },
      "outputs": [],
      "source": [
        "clf = RandomForestClassifier(random_state=22)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_uOWu1H5-JR"
      },
      "source": [
        "Training the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yV7WfKqsipVN"
      },
      "outputs": [],
      "source": [
        "clf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMLVqcbLhD5S"
      },
      "source": [
        "## Making predictions\n",
        "\n",
        "We set a classification threshold first.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uUnS9L41vmi-"
      },
      "outputs": [],
      "source": [
        "t=0.5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1Vnl5DFE-0d"
      },
      "source": [
        "### Predictions on the training set\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNZxtZM8vLmE"
      },
      "source": [
        "Computing ROC-AUC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BfJhVYL9BOwH"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RDOYhNOYAaKc"
      },
      "outputs": [],
      "source": [
        "prob_est_train = clf.predict_proba(X_train)\n",
        "roc_train = roc_auc_score(y_train, prob_est_train[:, 1].T)\n",
        "print('The {} has an ROC-AUC on the training set of {}'.format('Random Forest', roc_train))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8S96ALz16kRz"
      },
      "source": [
        "Plotting the Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJIaxcVtCFOO"
      },
      "outputs": [],
      "source": [
        "y_pred_train_rf = np.where(prob_est_train[:,1] > t, 1, 0)\n",
        "cm_rf_train = confusion_matrix(y_true=y_train, y_pred=y_pred_train_rf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uC3sI27H6ejl"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "plt.figure(figsize=(5, 5))\n",
        "sns.heatmap(cm_rf_train, annot=True, fmt=\"d\")\n",
        "plt.title('Confusion matrix for {}'.format('Random Forest on Training Set'))\n",
        "plt.ylabel('Actual label')\n",
        "plt.xlabel('Predicted label')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tr6RC3U-D4gr"
      },
      "source": [
        "### Predictions on the testing set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Mu1FaTxB03h"
      },
      "outputs": [],
      "source": [
        "prob_est_test_rf = clf.predict_proba(X_test)\n",
        "roc_test_rf = roc_auc_score(y_test, prob_est_test_rf[:, 1].T)\n",
        "print('The {} has an ROC-AUC on the testing set of {}'.format('Random Forest', roc_test_rf))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IhJuxSi7QDE"
      },
      "source": [
        "Plotting the Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-VSh43z68XD"
      },
      "outputs": [],
      "source": [
        "y_pred_test_rf = np.where(prob_est_test_rf[:,1] > t, 1, 0)\n",
        "cm_rf_test = confusion_matrix(y_true=y_test, y_pred = y_pred_test_rf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sffWPIJy_gB-"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "plt.figure(figsize=(5, 5))\n",
        "sns.heatmap(cm_rf_test, annot=True, fmt=\"d\")\n",
        "plt.title('Confusion matrix for {}'.format('Random Forest on Testing Set'))\n",
        "plt.ylabel('Actual label')\n",
        "plt.xlabel('Predicted label')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vm9HlkROvYzB"
      },
      "source": [
        "Calculating further metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_J_7c5Bm7hym"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iGtQGSc37hg5"
      },
      "outputs": [],
      "source": [
        "print(classification_report(y_test, y_pred_test_rf))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evzE3oAixeGJ"
      },
      "source": [
        "Deep-dive into model predictions. Which features are driving the model?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TnRQJ78NvDwY"
      },
      "outputs": [],
      "source": [
        "feature_importances = clf.feature_importances_\n",
        "\n",
        "# Create a DataFrame for better visualization\n",
        "importance_df = pd.DataFrame({\n",
        "    \"Feature\": X_train.columns,\n",
        "    \"Importance\": feature_importances\n",
        "}).sort_values(by=\"Importance\", ascending=False)\n",
        "print(importance_df[0:15])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECq6bvdQARNi"
      },
      "source": [
        "Let's use the SHAP framework. The model might take some time to run so account for multiple minutes for this operation to run."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IU9Bx9NqvDwY"
      },
      "outputs": [],
      "source": [
        "import shap\n",
        "clf.set_params(n_jobs=-1)\n",
        "explainer = shap.TreeExplainer(clf, approximate=True)\n",
        "\n",
        "sample_size = int(50)  # sample dataset\n",
        "\n",
        "\n",
        "sample_indices = np.random.choice(len(X_test), sample_size, replace=True)\n",
        "X_sample = X_test.iloc[sample_indices].copy()\n",
        "shap_values_sample = explainer.shap_values(X_sample)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.title(\"SHAP Summary Plot for Random Forest\")\n",
        "shap.summary_plot(shap_values_sample[:, :, 1] ,X_sample, feature_names=X_sample.columns)"
      ],
      "metadata": {
        "id": "Ey1H7PpAEchk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGQ0J6F7ZB-m"
      },
      "source": [
        "# 5. Training of Algorithm # 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FsbFFrwj7bhs"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import keras.metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQO9h43BAf49"
      },
      "source": [
        "### Defining the metrics for the evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4lauWivO9BXv"
      },
      "outputs": [],
      "source": [
        "METRICS = [\n",
        "    keras.metrics.TruePositives(name='tp'),\n",
        "    keras.metrics.FalsePositives(name='fp'),\n",
        "    keras.metrics.TrueNegatives(name='tn'),\n",
        "    keras.metrics.FalseNegatives(name='fn'),\n",
        "    keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "    keras.metrics.AUC(name='auc'),\n",
        "    keras.metrics.AUC(name='prc', curve='PR'),\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3yx568N8X_Z"
      },
      "source": [
        "### Loading the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "07qB0bjAwVCh"
      },
      "outputs": [],
      "source": [
        "# Setting the number of layers and neurons per layer\n",
        "neurons = 70\n",
        "hidden_layers = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pJ4MElxyOoNw"
      },
      "outputs": [],
      "source": [
        "# Calculating the initial bias\n",
        "neg, pos = np.bincount(target)\n",
        "initial_bias = np.log([pos / neg])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cWEbWWarpBs8"
      },
      "outputs": [],
      "source": [
        "# Splitting the data into training and validation sets\n",
        "X_train_ann, X_val_ann, y_train_ann, y_val_ann = train_test_split(X_train, y_train, test_size=0.2, stratify=y_train,\n",
        "                                                          random_state=44)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GAGl7Baq76x8"
      },
      "outputs": [],
      "source": [
        "# Initialising the model\n",
        "ann = tf.keras.models.Sequential()\n",
        "\n",
        "# Adding fully connected layers\n",
        "for layers in range(hidden_layers):\n",
        "    ann.add(tf.keras.layers.Dense(units=neurons, activation='relu'))\n",
        "\n",
        "ann.add(tf.keras.layers.Dropout(0.2))                                                           # Add a dropout layer\n",
        "ann.add(tf.keras.layers.Dense(units=1,activation='sigmoid', bias_initializer=tf.keras.initializers.Constant(initial_bias)))    # Add the output layer\n",
        "\n",
        "# Compiling the model\n",
        "ann.compile(optimizer= tf.optimizers.Adam(learning_rate=0.01), loss='binary_crossentropy', metrics=METRICS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jgzl6r7N9qfe"
      },
      "source": [
        "Training of the model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1XlHMEbM9VAi"
      },
      "outputs": [],
      "source": [
        "baseline_history = ann.fit(X_train_ann,\n",
        "                           y_train_ann,\n",
        "                           batch_size=32,\n",
        "                           epochs=100,\n",
        "                           validation_data=(X_val_ann, y_val_ann),\n",
        "                           )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R71fsENy4-KX"
      },
      "source": [
        "## Making predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7C-cpgzS3GTA"
      },
      "source": [
        "### Predictions on the training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "owdRCu-6-Gf0"
      },
      "outputs": [],
      "source": [
        "plt.plot(baseline_history.epoch, baseline_history.history['auc'])\n",
        "# print('The {} has an ROC-AUC on the training set of {}'.format('Neural Network', roc_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R7EM6-UkCIpQ"
      },
      "outputs": [],
      "source": [
        "t2 =0.5\n",
        "train_predictions_baseline = pd.DataFrame(ann.predict(X_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J1A4bHaJTM5E"
      },
      "outputs": [],
      "source": [
        "roc_train_ann = roc_auc_score(y_train, train_predictions_baseline.iloc[:, 0])\n",
        "print('The {} has an ROC-AUC on the training set of {}'.format('Neural Network', roc_train_ann))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fXgrF9cuCcWi"
      },
      "outputs": [],
      "source": [
        "confusion_train_ann = confusion_matrix(y_true= y_train, y_pred = train_predictions_baseline.iloc[:, 0] > t2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3qwcUkAwYE2"
      },
      "source": [
        "Plotting the Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yf-cQFId9-e_"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "plt.figure(figsize=(5, 5))\n",
        "sns.heatmap(confusion_train_ann, annot=True, fmt=\"d\")\n",
        "plt.title('Confusion matrix for {}'.format('Neural Network on Training Set'))\n",
        "plt.ylabel('Actual label')\n",
        "plt.xlabel('Predicted label')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "delbR2L1-Gfz"
      },
      "source": [
        "### Predictions on the testing set\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sCOhh0qNLQOL"
      },
      "outputs": [],
      "source": [
        "ann_predictions_test = pd.DataFrame(ann.predict(X_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sJKDJUu0NO19"
      },
      "outputs": [],
      "source": [
        "roc_test_ann = roc_auc_score(y_test, ann_predictions_test.iloc[:, 0])\n",
        "print('The {} has an ROC-AUC on the testing set of {}'.format('Neural Network', roc_test_ann))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OK-6ZUAKgX16"
      },
      "outputs": [],
      "source": [
        "confusion_test_ann = confusion_matrix(y_true= y_test, y_pred = ann_predictions_test.iloc[:, 0] > t2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tt3JyAH_weJT"
      },
      "source": [
        "Plotting the Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "BdUsFj09hOMd"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "plt.figure(figsize=(5, 5))\n",
        "sns.heatmap(confusion_test_ann, annot=True, fmt=\"d\")\n",
        "plt.title('Confusion matrix for {}'.format('Neural Network on Testing Set'))\n",
        "plt.ylabel('Actual label')\n",
        "plt.xlabel('Predicted label')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plotting SHAP for ANN"
      ],
      "metadata": {
        "id": "C_6ApJS9EqOJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "background = X_train_ann.sample(50, random_state=42).astype(np.float32).values\n",
        "\n",
        "sample_size = 50\n",
        "sample_indices = np.random.choice(len(X_test), sample_size, replace=True)\n",
        "X_sample_np = X_test.iloc[sample_indices].copy().astype(np.float32).values\n",
        "X_sample_df = pd.DataFrame(X_sample_np, columns=X_test.columns)\n",
        "\n",
        "\n",
        "explainer_ANN = shap.DeepExplainer(ann, background)\n",
        "shap_values_ANN = explainer_ANN.shap_values(X_sample_np)"
      ],
      "metadata": {
        "id": "m29TMaSZEkra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the summary plot using the SHAP values for the output (index 0)\n",
        "plt.title(\"SHAP Summary Plot for ANN\")\n",
        "shap.summary_plot(np.squeeze(shap_values_ANN, axis=-1), X_sample_df, feature_names=X_sample_df.columns)"
      ],
      "metadata": {
        "id": "T0GnxQcREoiB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djxXN_hT6wu8"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjh1lsx4ZBhx"
      },
      "source": [
        "# Your Assignment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fegQ1p61ZBUO"
      },
      "source": [
        "First, do make sure to have added your **candidate number** at the top!\n",
        "\n",
        "Then run the above notebook, and **answer the following  questions** (all parts are weighted as indicated in the parentheses at the beginning of each question):\n",
        "\n",
        "1.   (20%) State what kind of machine learning algorithms have been implemented in this workbook and briefly interpret the results obtained. In addition, discuss the advantages and limitations of the two modeling approaches taken here. Justify your answer based on the specific case study and results you observe!\n",
        "\n",
        "2.   (30%) Based on the data provided, compare the key factors driving the predictive power of the proposed learners and explain whether they match your intuition. Are there any features that you would like to exclude or further investigate? If yes, why? Leveraging your insights from Questions 1-2, state which approach you would propose to Anna to implement for the task at hand.\n",
        "\n",
        "3.   (30%) Propose potential ways to understand better and improve the performance of the derived models to Anna. Are there other machine learning algorithms, data sources, data pre-processing, or model post-processing techniques that she could use to improve these results? Your answer here is expected to be descriptive (coding is not necessary). However, we expect you to provide arguments, using the course materials, to justify your suggestions. In your answers, keep into consideration the cost, feasibility, and effectiveness of your recommendations for this particular business context.\n",
        "\n",
        "4.  (20%) Suppose that you conclude with Anna that one of the models can proceed into implementation. Are there additional tests or analyses that you would like to conduct before integrating the model into the stores' IT system? What are some potential challenges that you foresee and how do you expect to remedy these challenges?\n",
        "\n",
        "5.  (OPTIONAL) You can add your own code to the notebook to improve the predictive performance of the derived models or support with additional evidence your answers to questions 1-4. You can suggest modified or new models, using other algorithms or implement some of your suggestions from Q3. If you decide to do so, indicate your changes with an appropriate text comment before each cell. Of note, submitting your own code to the assignment will not \"hurt\" (reduce) your grade. However, please ensure that your code runs without any errors before the submission and that the output of the models is printed. Remember that this part is optional and can only help you towards a distinction in the class. You can use open-access large language models, such as ChatGPT or BARD for the optional \"coding\" part of the assignment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZCwK2DsZBFb"
      },
      "source": [
        "# Your answer (1,500 words max)\n",
        "\n",
        "Word counts cover the main body of text, including in-text citations, tables, figures, and diagrams, but excluding appendices, footnotes, references, as well as any python code or comments that you add to the notebook as part of the optional question."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGvpW2V9Zjp4"
      },
      "source": [
        "*(Please type here)*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvsqqcqn60QH"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cevlSVE5ZmpT"
      },
      "source": [
        "***Now Save your notebook, print it as PDF, and submit the PDF to SAMS!***"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}